# Python analysis template

[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository serves as a personal template for data science projects.

The template comes with the following features/customisations:

- The project is organised as a research compendium (see the [File Structure](#file-structure) section).
- [Visual Studio Code](https://code.visualstudio.com/) is used as an IDE, along with [various extensions](.vscode/extensions.json).
- A [VS Code Dev Container](https://code.visualstudio.com/docs/devcontainers/containers) ([Docker](https://www.docker.com/)) is used as a preferred development environment.
- [pre-commit](https://pre-commit.com/) is used to manage git hooks.
- Python tooling
  - [Black](https://black.readthedocs.io/en/stable/index.html) is used as a formatter (pre-commit and VSC extension).
  - [Ruff](https://docs.astral.sh/ruff/) (pre-commit and VSC extension) and [SonarLint](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarlint-vscode) (VSC extension) are used as linters.
  - [mypy](https://www.mypy-lang.org/) is used as a type checker (VSC extension).
  - [uv](https://docs.astral.sh/uv/) is used to compile requirements (not as a package manager, yet).
  - [pdoc](https://pdoc.dev/docs/pdoc.html) is used to generate API documentation.
    Python docstrings are written following the [Google docstring format](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html) and with the help of the [autoDocstring VSC extension](https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring).
  - Automatic versioning of the local package from git tags using [setuptools_scm](https://setuptools-scm.readthedocs.io/en/stable/), following [semantic versioning](https://semver.org/).
- [SQLFluff](https://sqlfluff.com/) is used as a linter and formatter for SQL files (pre-commit and VSC extension).
- [prettier](https://prettier.io/) (VSC extension) is used as a formatter for YAML, JSON and Markdown files.
- [Taplo](https://marketplace.visualstudio.com/items?itemName=tamasfe.even-better-toml) (VSC extension) as a formatter for TOML files
- [Make](https://www.gnu.org/software/make/) is used as an interface to various utility scripts (see the [Make commands](#make-commands) section).

## File structure

```
.
├── analysis/              # Notebooks and analysis scripts
├── data/                  # Data files (usually git ignored)
├── docs/                  # API documentation (git ignored)
├── results/               # Output files: figures, tables, etc. (git ignored)
├── src/                   # Local Python package
│   ├── __init__.py
│   └── config.py          # Configs, constants, settings
├── tests/                 # Unit tests for src/
│   └── test_*.py
├── .devcontainer/         # VS Code dev container setup
├── .vscode/               # VS Code settings and extensions
├── scripts/               # Utility scripts (e.g. env setup)
├── Makefile               # Utility commands (docs, env, versioning)
├── pyproject.toml         # Package/Project configuration, direct dependencies
├── requirements.txt       # Pinned dependencies (generated)
```

## Development environment

The preferred development environment for this project is a **VS Code Dev Container**, which provides a consistent and reproducible setup using Docker.

1. Install and launch [Docker](https://www.docker.com/).
2. Install and open the project in VS Code.
3. Open the container by using the command palette in VS Code (`Ctrl + Shift + P`) to search for "Dev Containers: Open Folder in Container...".

Once inside the container, the dependencies specified in [`requirements.txt`](requirements.txt) are installed and the local package is available in editable mode.
If needed, the container can be rebuilt by searching for "Dev Containers: Rebuild Container...".

For more details regarding Dev Containers, or alternative environment setups (venv, conda, etc.), please refer to [`DEVELOPMENT.md`](DEVELOPMENT.md).

Regardless of the environment, install Git hooks after setup with `pre-commit install` to ensure the code is automatically linted and formatted on commit.

## Managing requirements

The requirements are specified in the following files:

- [`pyproject.toml`](pyproject.toml) to store the direct dependencies of the `src` package and development dependencies (e.g. for the analysis).
- [`requirements.txt`](requirements.txt) to pin the dependencies (direct and indirect).
  This file is automatically generated with [`uv`](https://docs.astral.sh/uv/) and can then be used to recreate the environment from scratch.

NB: the [`requirements.txt`](requirements.txt) file does not include the local package (`src`), hence the two-steps process of installing dependencies.

### Initial setup

1. Start with an empty `requirements.txt`.
2. Install uv with `pip install uv`.
3. Compile requirements with `uv pip compile pyproject.toml -o requirements.txt --all-extras` (or `make reqs`) to generate a `requirements.txt` file.
4. Install requirements with `pip install -r requirements.txt` and then the local package with `pip install -e .[all]`.

### Update the environment

- To upgrade packages, run `uv pip compile pyproject.toml -o requirements.txt --all-extras --upgrade`.
- To add new packages, add packages in `pyproject.toml` and then compile requirements as above.

## Make commands

A Makefile is provided as an interface to various utility scripts:

- `make docs` to generate the package documentation.
- `make reqs` to compile requirements.
- `make deps` to install requirements in [`requirements.txt`](requirements.txt) and the local package.
- `make tag` to add and push a new Git tag by incrementing the version.
- `make venv` to setup a venv environment (see [`scripts/setup_venv.sh`](scripts/setup_venv.sh)).

## Using the template

> This section can be deleted when using the template.

### Getting started

1. Initialise your GitHub repository with this template. Alternatively, fork (or copy the content of) this repository.
2. Update
   - [ ] project information in [`pyproject.toml`](pyproject.toml), such as the description and the authors.
   - [ ] the repository name (if the template was forked).
   - [ ] the README (title, badges, sections).
   - [ ] the license.
3. Set up your preferred development environment (see the [Development Environment section](#development-environment)).
4. Add a git tag for the inital version with `git tag -a v0.1.0 -m "Initial setup"`, and push it with `git push origin --tags`. Alternatively, use `make tag`.

### Possible extensions

The `src/` package could contain the following modules or sub-packages depending on the project:

- `utils` for utility functions.
- `data_processing` or `data` for data processing functions.
- `features`: for extracting features.
- `models`: for defining models.
- `evaluation`: for evaluating performance.
- `plots`: for plotting functions.

The repository structure could be extended with:

- subfolders in `data/` such as `data/raw/` for storing raw data.
- `models/` to store model files.

Finally, a full project documentation (beyond the API) could be generated using [mkdocs](https://www.mkdocs.org/) or [quartodoc](https://machow.github.io/quartodoc/get-started/overview.html).

### Related

This template is inspired by the concept of a [research compendium](https://doi.org/10.1080/00031305.2017.1375986) and similar projects I created for R projects (e.g. [reproducible-workflow](https://github.com/ghurault/reproducible-workflow)).

This template is relatively simple and tailored to my needs.
More sophisticated templates are available elsewhere, such as:

- [Cookiecutter Data Science](https://github.com/drivendataorg/cookiecutter-data-science/).
- [https://joserzapata.github.io/data-science-project-template/](https://joserzapata.github.io/data-science-project-template/)
- [Data Science for Social Good's hitchhikers guide template](https://github.com/dssg/hitchhikers-guide/tree/master/sources/curriculum/0_before_you_start/pipelines-and-project-workflow)
- [https://github.com/khuyentran1401/data-science-template](https://github.com/khuyentran1401/data-science-template)

As opposed to other templates, this template is more focused on experimentation rather than sharing a single final product.
